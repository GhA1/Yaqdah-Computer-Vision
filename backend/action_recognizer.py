from transformers import VideoMAEImageProcessor, VideoMAEForVideoClassification
import numpy as np
import torch
import cv2

class ActionRecognizer:
    def __init__(self):
        print("Loading VideoMAE Model...")
        model_ckpt = "MCG-NJU/videomae-base-finetuned-kinetics"
        
        try:
            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'
            self.processor = VideoMAEImageProcessor.from_pretrained(model_ckpt)
            self.model = VideoMAEForVideoClassification.from_pretrained(model_ckpt).to(self.device)
            print(f"âœ… VideoMAE Loaded on {self.device}.")
        except Exception as e:
            print(f"âŒ Error: {e}")
            self.model = None

        # ====================================================
        # âš ï¸ Ù‚Ø§Ù…ÙˆØ³ Ø§Ù„Ø®Ø·Ø± (ØªÙ… Ø§Ù„ØªØ­Ø¯ÙŠØ« Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø³Ø¬Ù„Ø§Øª)
        # ====================================================
# Ø£Ø±Ø¬Ø¹ Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ù†Ø¸ÙŠÙØ© (Ø§Ø­Ø°Ù motorcycling Ùˆ driving Ùˆ skateboarding)
        self.danger_keywords = [
            'fighting', 'punching', 'kicking', 'slapping', 'brawling', 
            'stabbing', 'hitting', 'headbutting', 'wrestling', 'choking',
            'drop kicking', 'shooting', 'sword', 'gun', 'knife',
            'weapon', 'pushing car' # Ø£Ø¨Ù‚Ù parkour Ø¥Ø°Ø§ ÙƒÙ†Øª ØªØ¹ØªØ¨Ø±Ù‡Ø§ Ø®Ø·Ø±Ø©
        ]

    def predict(self, frame_buffer):
        if self.model is None or len(frame_buffer) < 16:
            return "Buffering...", False, 0.0

        try:
            # ØªØ¬Ù‡ÙŠØ² Ø§Ù„ÙØ±ÙŠÙ…Ø§Øª
            indices = np.linspace(0, len(frame_buffer) - 1, 16).astype(int)
            clip = [frame_buffer[i] for i in indices]
            clip_rgb = [cv2.cvtColor(img, cv2.COLOR_BGR2RGB) for img in clip]

            inputs = self.processor(list(clip_rgb), return_tensors="pt").to(self.device)

            with torch.no_grad():
                outputs = self.model(**inputs)
                logits = outputs.logits

            probs = torch.nn.functional.softmax(logits, dim=-1)
            
            # ==========================================================
            # ğŸ”¥ Ø§Ù„ØªØºÙŠÙŠØ± Ø§Ù„Ø¬ÙˆÙ‡Ø±ÙŠ: ÙØ­Øµ Ø£Ø¹Ù„Ù‰ 5 Ù†ØªØ§Ø¦Ø¬ Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† Ø§Ù„Ø£ÙˆÙ„Ù‰ ÙÙ‚Ø·
            # ==========================================================
            top5_prob, top5_indices = torch.topk(probs, 5)
            
            final_label = "Normal"
            final_conf = 0.0
            is_danger = False
            
            print("\nğŸ” AI Scan (Top 5):")
            
            for i in range(5):
                label_text = self.model.config.id2label[top5_indices[0][i].item()]
                score = top5_prob[0][i].item() * 100
                print(f"   {i+1}. {label_text}: {score:.1f}%")
                
                # Ø§Ù„ØªØ­Ù‚Ù‚ Ù‡Ù„ Ù‡Ø°Ù‡ Ø§Ù„ÙƒÙ„Ù…Ø© Ø®Ø·Ø±Ø©ØŸ
                if any(k in label_text.lower() for k in self.danger_keywords):
                    is_danger = True
                    final_label = label_text # Ù†Ø£Ø®Ø° Ø§Ø³Ù… Ø§Ù„Ø®Ø·Ø± Ø­ØªÙ‰ Ù„Ùˆ ÙƒØ§Ù† ØªØ±ØªÙŠØ¨Ù‡ Ø§Ù„Ø«Ø§Ù„Ø«
                    final_conf = score       # Ù†Ø£Ø®Ø° Ù†Ø³Ø¨ØªÙ‡
                    print(f"      >>> âš ï¸ DETECTED THREAT: {label_text}")
                    break # ÙˆØ¬Ø¯Ù†Ø§ Ø®Ø·Ø±ØŒ Ù†ØªÙˆÙ‚Ù Ø¹Ù† Ø§Ù„Ø¨Ø­Ø« ÙˆÙ†Ø¨Ù„Øº ÙÙˆØ±Ø§Ù‹

            # Ø¥Ø°Ø§ Ù„Ù… Ù†Ø¬Ø¯ Ø®Ø·Ø±Ø§Ù‹ ÙÙŠ Ø§Ù„Ù€ 5 Ø§Ù„Ø£ÙˆØ§Ø¦Ù„ØŒ Ù†Ø£Ø®Ø° Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø±Ù‚Ù… 1 ÙƒØ§Ù„Ø¹Ø§Ø¯Ø©
            if not is_danger:
                final_label = self.model.config.id2label[top5_indices[0][0].item()]
                final_conf = top5_prob[0][0].item() * 100

            # ØªÙˆØ­ÙŠØ¯ Ø§Ù„Ù…Ø³Ù…Ù‰ Ù„Ù„Ø¹Ø±Ø¶
            display_label = "Violence Detected" if is_danger else final_label

            return display_label, is_danger, final_conf

        except Exception as e:
            print(f"Error: {e}")
            return "Error", False, 0.0